#!/usr/bin/env python3
"""
Quick Coverage Check - An√°lise R√°pida de Cobertura
Identifica problemas urgentes e m√≥dulos priorit√°rios para corre√ß√£o
"""

import os
import sys
import subprocess
import json
from pathlib import Path
from typing import Dict, List, Tuple
import tempfile

class QuickCoverageAnalyzer:
    def __init__(self, project_root: str = None):
        self.project_root = Path(project_root) if project_root else Path.cwd()
        self.src_dir = self.project_root / "src"
        self.tests_dir = self.project_root / "tests"
        
        # M√≥dulos cr√≠ticos com 0% cobertura
        self.critical_zero_coverage = [
            "template_renderer.py",
            "language_aware_chunker.py", 
            "adaptive_rag_router.py",
            "memo_rag.py",
            "multi_head_rag.py",
            "raptor_simple.py",
            "colbert_reranker.py"
        ]
        
        # M√≥dulos com baixa cobertura priorit√°rios
        self.low_coverage_priority = [
            "rag_pipeline_advanced.py",
            "api_model_router.py",
            "model_router.py",
            "qdrant_store.py"
        ]

    def test_basic_imports(self) -> Dict[str, bool]:
        """Testa se m√≥dulos b√°sicos podem ser importados"""
        print("üîç Testando importa√ß√µes b√°sicas...")
        
        results = {}
        basic_modules = [
            ("src.settings", "Settings b√°sico"),
            ("src.template_renderer", "Template Renderer"),
            ("src.prompt_selector", "Prompt Selector")
        ]
        
        for module, description in basic_modules:
            try:
                # Teste de importa√ß√£o isolado
                test_code = f"import sys; sys.path.insert(0, 'src'); import {module.replace('src.', '')}; print('‚úÖ OK')"
                result = subprocess.run([
                    sys.executable, "-c", test_code
                ], capture_output=True, text=True, cwd=self.project_root, timeout=10)
                
                success = result.returncode == 0
                results[module] = success
                
                status = "‚úÖ OK" if success else "‚ùå FALHA"
                print(f"  {status} {description}")
                
                if not success:
                    print(f"    Erro: {result.stderr.strip()}")
                    
            except Exception as e:
                results[module] = False
                print(f"  ‚ùå FALHA {description}: {e}")
        
        return results

    def identify_problematic_modules(self) -> List[Tuple[str, str, str]]:
        """Identifica m√≥dulos problem√°ticos por depend√™ncia"""
        print("\nüîç Identificando m√≥dulos problem√°ticos...")
        
        problematic = []
        
        # Verificar m√≥dulos que dependem de sentence-transformers
        sentence_transformer_modules = [
            ("src/chunking/language_aware_chunker.py", "sentence-transformers", "CR√çTICO"),
            ("src/chunking/semantic_chunker.py", "sentence-transformers", "M√âDIO"),
            ("src/chunking/semantic_chunker_enhanced.py", "sentence-transformers", "M√âDIO")
        ]
        
        # Verificar m√≥dulos que dependem de qdrant
        qdrant_modules = [
            ("src/vectordb/qdrant_store.py", "qdrant-client", "CR√çTICO"),
            ("src/vectordb/hybrid_qdrant_store.py", "qdrant-client", "CR√çTICO")
        ]
        
        # Verificar m√≥dulos que dependem de openai
        openai_modules = [
            ("src/models/api_model_router.py", "openai", "CR√çTICO"),
            ("src/embeddings/api_embedding_service.py", "openai", "CR√çTICO")
        ]
        
        all_modules = sentence_transformer_modules + qdrant_modules + openai_modules
        
        for module_path, dependency, priority in all_modules:
            full_path = self.project_root / module_path
            if full_path.exists():
                problematic.append((module_path, dependency, priority))
                print(f"  üî¥ {priority}: {module_path} (dep: {dependency})")
            
        return problematic

    def check_test_files_status(self) -> Dict[str, str]:
        """Verifica status dos arquivos de teste"""
        print("\nüìù Verificando status dos arquivos de teste...")
        
        test_status = {}
        
        # Verificar testes para m√≥dulos cr√≠ticos
        for module in self.critical_zero_coverage:
            test_name = f"test_{module.replace('.py', '')}"
            
            # Procurar por arquivos de teste
            test_files = list(self.tests_dir.glob(f"{test_name}*.py"))
            
            if test_files:
                status = f"‚úÖ Existe ({len(test_files)} arquivos)"
                # Verificar se o teste √© funcional
                try:
                    result = subprocess.run([
                        sys.executable, "-m", "pytest", str(test_files[0]), "--collect-only"
                    ], capture_output=True, text=True, cwd=self.project_root, timeout=10)
                    
                    if result.returncode != 0:
                        status = f"‚ö†Ô∏è Existe mas problem√°tico"
                        
                except Exception:
                    status = f"‚ùå Existe mas n√£o executa"
            else:
                status = "‚ùå N√£o existe"
            
            test_status[module] = status
            print(f"  {module}: {status}")
        
        return test_status

    def suggest_immediate_actions(self, import_results: Dict, problematic: List, test_status: Dict):
        """Sugere a√ß√µes imediatas baseadas na an√°lise"""
        print("\nüéØ A√á√ïES IMEDIATAS RECOMENDADAS:")
        
        # 1. Problemas de conftest.py
        if not all(import_results.values()):
            print("\n1Ô∏è‚É£ URGENTE: Corrigir conftest.py")
            print("   - Problemas de importa√ß√£o detectados")
            print("   - Implementar mocks para depend√™ncias pesadas")
            print("   - Comando: cp tests/conftest.py tests/conftest.py.backup")
            
        # 2. Testes inexistentes
        missing_tests = [module for module, status in test_status.items() if "‚ùå N√£o existe" in status]
        if missing_tests:
            print(f"\n2Ô∏è‚É£ ALTA PRIORIDADE: Criar testes b√°sicos ({len(missing_tests)} m√≥dulos)")
            for module in missing_tests[:3]:  # Top 3
                print(f"   - {module} (0% cobertura)")
            
        # 3. Depend√™ncias problem√°ticas
        critical_deps = [p for p in problematic if p[2] == "CR√çTICO"]
        if critical_deps:
            print(f"\n3Ô∏è‚É£ M√âDIO PRAZO: Resolver depend√™ncias cr√≠ticas ({len(critical_deps)} m√≥dulos)")
            deps = set(p[1] for p in critical_deps)
            for dep in deps:
                print(f"   - Mock para {dep}")
        
        # 4. Pr√≥ximos passos
        print("\n4Ô∏è‚É£ PR√ìXIMOS PASSOS:")
        print("   1. python scripts/boost_test_coverage.py --phase=1")
        print("   2. Criar teste b√°sico para template_renderer.py (mais simples)")
        print("   3. python -m pytest tests/test_template_renderer.py --cov=src.template_renderer")
        print("   4. Expandir para language_aware_chunker.py")

    def run_quick_test(self) -> bool:
        """Executa teste r√°pido em m√≥dulos funcionais"""
        print("\n‚ö° Executando teste r√°pido em m√≥dulos funcionais...")
        
        try:
            # Testar apenas m√≥dulos que sabemos que funcionam
            functional_tests = [
                "tests/test_settings.py",
                "tests/test_prompt_selector.py"
            ]
            
            existing_tests = [t for t in functional_tests if (self.project_root / t).exists()]
            
            if existing_tests:
                result = subprocess.run([
                    sys.executable, "-m", "pytest"
                ] + existing_tests + [
                    "--cov=src", "--cov-report=term-missing", "-v", "--tb=short"
                ], capture_output=True, text=True, cwd=self.project_root, timeout=60)
                
                success = result.returncode == 0
                print(f"{'‚úÖ' if success else '‚ùå'} Teste r√°pido: {'PASSOU' if success else 'FALHOU'}")
                
                if success:
                    # Extrair informa√ß√£o de cobertura
                    if "TOTAL" in result.stdout:
                        lines = result.stdout.split('\n')
                        for line in lines:
                            if "TOTAL" in line and "%" in line:
                                print(f"  üìä {line.strip()}")
                
                return success
            else:
                print("‚ö†Ô∏è Nenhum teste funcional encontrado")
                return False
                
        except Exception as e:
            print(f"‚ùå Erro no teste r√°pido: {e}")
            return False

    def create_emergency_conftest(self):
        """Cria conftest.py de emerg√™ncia com mocks b√°sicos"""
        print("\nüöë Criando conftest.py de emerg√™ncia...")
        
        emergency_conftest = '''"""
Conftest de emerg√™ncia com mocks b√°sicos
Criado automaticamente pelo QuickCoverageAnalyzer
"""

import pytest
from unittest.mock import Mock, patch, MagicMock
import sys
from pathlib import Path

# Adicionar src ao path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

@pytest.fixture(scope="session", autouse=True)
def mock_heavy_dependencies():
    """Mock autom√°tico para depend√™ncias pesadas"""
    mocks = {}
    
    # Mock sentence-transformers
    try:
        with patch('sentence_transformers.SentenceTransformer') as mock_st:
            mock_st.return_value.encode.return_value = [[0.1] * 384]
            mocks['sentence_transformer'] = mock_st
            yield mocks
    except:
        pass
    
    # Mock qdrant-client
    try:
        with patch('qdrant_client.QdrantClient') as mock_qc:
            mock_qc.return_value.search.return_value = []
            mocks['qdrant_client'] = mock_qc
    except:
        pass
    
    # Mock openai
    try:
        with patch('openai.OpenAI') as mock_openai:
            mock_response = Mock()
            mock_response.data = [Mock(embedding=[0.1] * 1536)]
            mock_openai.return_value.embeddings.create.return_value = mock_response
            mocks['openai'] = mock_openai
    except:
        pass

@pytest.fixture
def sample_text():
    """Texto de exemplo para testes"""
    return "Este √© um texto de exemplo para testes de RAG."

@pytest.fixture
def sample_embedding():
    """Embedding de exemplo"""
    return [0.1] * 384

@pytest.fixture
def sample_query():
    """Query de exemplo"""
    return "Como funciona o sistema RAG?"
'''
        
        conftest_path = self.tests_dir / "conftest_emergency.py"
        with open(conftest_path, 'w', encoding='utf-8') as f:
            f.write(emergency_conftest)
        
        print(f"‚úÖ Conftest de emerg√™ncia criado: {conftest_path}")
        print("   Para usar: mv tests/conftest.py tests/conftest_old.py && mv tests/conftest_emergency.py tests/conftest.py")

    def main(self):
        """Executa an√°lise completa"""
        print("üöÄ Quick Coverage Check - An√°lise R√°pida\n" + "="*50)
        
        # 1. Testar importa√ß√µes b√°sicas
        import_results = self.test_basic_imports()
        
        # 2. Identificar m√≥dulos problem√°ticos
        problematic = self.identify_problematic_modules()
        
        # 3. Verificar arquivos de teste
        test_status = self.check_test_files_status()
        
        # 4. Executar teste r√°pido
        quick_test_passed = self.run_quick_test()
        
        # 5. Criar conftest de emerg√™ncia
        if not all(import_results.values()):
            self.create_emergency_conftest()
        
        # 6. Sugerir a√ß√µes
        self.suggest_immediate_actions(import_results, problematic, test_status)
        
        # 7. Resumo final
        print(f"\nüìä RESUMO:")
        print(f"   ‚úÖ Importa√ß√µes funcionais: {sum(import_results.values())}/{len(import_results)}")
        print(f"   üî¥ M√≥dulos problem√°ticos: {len(problematic)}")
        print(f"   üìù Testes existentes: {sum(1 for s in test_status.values() if '‚úÖ' in s)}/{len(test_status)}")
        print(f"   ‚ö° Teste r√°pido: {'PASSOU' if quick_test_passed else 'FALHOU'}")
        
        # Status geral
        if all(import_results.values()) and quick_test_passed:
            print(f"\nüéØ STATUS: ‚úÖ PRONTO PARA EXPANS√ÉO DE TESTES")
        elif any(import_results.values()):
            print(f"\nüéØ STATUS: ‚ö†Ô∏è PARCIALMENTE FUNCIONAL - CORRIGIR DEPEND√äNCIAS")
        else:
            print(f"\nüéØ STATUS: üî¥ CR√çTICO - RESOLVER CONFTEST.PY PRIMEIRO")

if __name__ == "__main__":
    analyzer = QuickCoverageAnalyzer()
    analyzer.main() 