#!/usr/bin/env python3
"""
Demonstra√ß√£o: Sistema Atual vs Sistema H√≠brido
Mostra a diferen√ßa entre usar uma API por resposta vs m√∫ltiplas APIs colaborativas
"""

import os
import time
from typing import Dict, List, Any
from dataclasses import dataclass

# Simula√ß√£o das APIs (substitua pelas implementa√ß√µes reais)
class MockAPIRouter:
    def generate_response(self, query: str, context: str = "", task_type: str = None, force_model: str = None):
        return {
            "content": f"Resposta simulada para: {query[:50]}...",
            "model": force_model or "gpt-4o-mini",
            "provider": force_model.split('.')[0] if force_model else "openai",
            "cost": 0.001,
            "processing_time": 1.2
        }

@dataclass
class HybridResponse:
    """Resposta de um sistema h√≠brido"""
    final_answer: str
    analysis_steps: List[Dict[str, Any]]
    total_cost: float
    total_time: float
    providers_used: List[str]

class SystemComparison:
    """Compara√ß√£o entre sistema atual e h√≠brido"""
    
    def __init__(self):
        self.router = MockAPIRouter()
    
    def sistema_atual_uma_api(self, query: str, context: str = "") -> Dict[str, Any]:
        """
        SISTEMA ATUAL: Uma √∫nica API por resposta
        - Detecta tipo de tarefa
        - Seleciona melhor modelo
        - Faz UMA chamada de API
        - Retorna resposta completa
        """
        print("üîÑ SISTEMA ATUAL - Uma API por resposta")
        print("-" * 50)
        
        start_time = time.time()
        
        # 1. Detectar tipo de tarefa
        if "c√≥digo" in query.lower() or "function" in query.lower():
            task_type = "code_generation"
            selected_model = "openai.gpt4o_mini"
        elif "analisar" in query.lower() or "documento" in query.lower():
            task_type = "document_analysis"
            selected_model = "anthropic.claude_3_5_sonnet"
        else:
            task_type = "general_explanation"
            selected_model = "openai.gpt4o"
        
        print(f"Tarefa detectada: {task_type}")
        print(f"Modelo selecionado: {selected_model}")
        
        # 2. UMA √∫nica chamada de API
        response = self.router.generate_response(
            query=query,
            context=context,
            force_model=selected_model
        )
        
        total_time = time.time() - start_time
        
        print(f"‚úÖ Resposta em {total_time:.2f}s")
        print(f"Custo: ${response['cost']:.4f}")
        print(f"Provedor usado: {response['provider']}")
        
        return {
            "answer": response["content"],
            "model_used": response["model"],
            "provider_used": response["provider"],
            "cost": response["cost"],
            "processing_time": total_time,
            "api_calls": 1
        }
    
    def sistema_hibrido_multiplas_apis(self, query: str, context: str = "") -> HybridResponse:
        """
        SISTEMA H√çBRIDO: M√∫ltiplas APIs colaborativas por resposta
        - An√°lise inicial (Claude para entender)
        - Gera√ß√£o de c√≥digo (OpenAI para implementar)
        - Revis√£o (DeepSeek para otimizar)
        - S√≠ntese final (GPT-4o para consolidar)
        """
        print("\nüîÑ SISTEMA H√çBRIDO - M√∫ltiplas APIs colaborativas")
        print("-" * 50)
        
        start_time = time.time()
        analysis_steps = []
        total_cost = 0.0
        providers_used = []
        
        # ETAPA 1: An√°lise e compreens√£o (Claude)
        print("1. üß† An√°lise inicial (Claude 3.5 Sonnet)")
        analysis_response = self.router.generate_response(
            query=f"Analise esta solicita√ß√£o e quebre em etapas: {query}",
            context=context,
            force_model="anthropic.claude_3_5_sonnet"
        )
        
        analysis_steps.append({
            "step": "analysis",
            "provider": "anthropic",
            "model": "claude_3_5_sonnet",
            "purpose": "An√°lise e quebra em etapas",
            "output": analysis_response["content"],
            "cost": analysis_response["cost"],
            "time": analysis_response["processing_time"]
        })
        
        total_cost += analysis_response["cost"]
        providers_used.append("anthropic")
        
        # ETAPA 2: Gera√ß√£o de c√≥digo (OpenAI)
        if "c√≥digo" in query.lower() or "function" in query.lower():
            print("2. üíª Gera√ß√£o de c√≥digo (GPT-4o-mini)")
            code_response = self.router.generate_response(
                query=f"Com base na an√°lise: {analysis_response['content'][:100]}..., gere o c√≥digo solicitado: {query}",
                context=context,
                force_model="openai.gpt4o_mini"
            )
            
            analysis_steps.append({
                "step": "code_generation",
                "provider": "openai",
                "model": "gpt4o_mini",
                "purpose": "Gera√ß√£o de c√≥digo",
                "output": code_response["content"],
                "cost": code_response["cost"],
                "time": code_response["processing_time"]
            })
            
            total_cost += code_response["cost"]
            providers_used.append("openai")
            
            # ETAPA 3: Otimiza√ß√£o (DeepSeek)
            print("3. ‚ö° Otimiza√ß√£o de c√≥digo (DeepSeek Coder)")
            optimization_response = self.router.generate_response(
                query=f"Otimize este c√≥digo: {code_response['content'][:200]}...",
                force_model="deepseek.deepseek_coder"
            )
            
            analysis_steps.append({
                "step": "optimization",
                "provider": "deepseek",
                "model": "deepseek_coder",
                "purpose": "Otimiza√ß√£o de c√≥digo",
                "output": optimization_response["content"],
                "cost": optimization_response["cost"],
                "time": optimization_response["processing_time"]
            })
            
            total_cost += optimization_response["cost"]
            providers_used.append("deepseek")
        
        # ETAPA 4: S√≠ntese final (GPT-4o)
        print("4. üìù S√≠ntese final (GPT-4o)")
        final_context = "\n".join([step["output"][:100] + "..." for step in analysis_steps])
        
        synthesis_response = self.router.generate_response(
            query=f"Sintetize as informa√ß√µes anteriores em uma resposta completa para: {query}",
            context=final_context,
            force_model="openai.gpt4o"
        )
        
        analysis_steps.append({
            "step": "synthesis",
            "provider": "openai",
            "model": "gpt4o",
            "purpose": "S√≠ntese e resposta final",
            "output": synthesis_response["content"],
            "cost": synthesis_response["cost"],
            "time": synthesis_response["processing_time"]
        })
        
        total_cost += synthesis_response["cost"]
        providers_used.append("openai")
        
        total_time = time.time() - start_time
        
        print(f"‚úÖ Resposta h√≠brida em {total_time:.2f}s")
        print(f"Custo total: ${total_cost:.4f}")
        print(f"Provedores usados: {', '.join(set(providers_used))}")
        print(f"Total de chamadas API: {len(analysis_steps)}")
        
        return HybridResponse(
            final_answer=synthesis_response["content"],
            analysis_steps=analysis_steps,
            total_cost=total_cost,
            total_time=total_time,
            providers_used=list(set(providers_used))
        )

def comparar_sistemas():
    """Compara os dois sistemas"""
    
    print("üîç COMPARA√á√ÉO: Sistema Atual vs Sistema H√≠brido")
    print("=" * 60)
    
    query = "Crie uma fun√ß√£o Python para calcular fibonacci otimizada e explique como funciona"
    
    print(f"Query: {query}")
    
    # SISTEMA ATUAL - UMA API POR RESPOSTA
    print("\nüîÑ SISTEMA ATUAL - Uma API por resposta")
    print("-" * 50)
    print("1. Detecta tarefa: code_generation")
    print("2. Seleciona modelo: openai.gpt4o_mini")
    print("3. UMA chamada API ‚Üí Resposta completa")
    print("‚úÖ Resultado: C√≥digo + explica√ß√£o em uma resposta")
    print("Custo: $0.001 | Tempo: 2s | APIs: 1")
    
    # SISTEMA H√çBRIDO - M√öLTIPLAS APIs COLABORATIVAS
    print("\nüîÑ SISTEMA H√çBRIDO - M√∫ltiplas APIs colaborativas")
    print("-" * 50)
    print("1. üß† Claude analisa requisitos")
    print("2. üíª OpenAI gera c√≥digo inicial")
    print("3. ‚ö° DeepSeek otimiza performance")
    print("4. üìù GPT-4o sintetiza explica√ß√£o final")
    print("‚úÖ Resultado: C√≥digo otimizado + explica√ß√£o detalhada")
    print("Custo: $0.008 | Tempo: 6s | APIs: 4")
    
    print("\nüìä COMPARA√á√ÉO FINAL")
    print("=" * 60)
    
    print(f"{'M√©trica':<25} {'Sistema Atual':<20} {'Sistema H√≠brido':<20}")
    print("-" * 65)
    print(f"{'Chamadas API':<25} {'1':<20} {'4':<20}")
    print(f"{'Custo T√≠pico':<25} {'$0.001':<20} {'$0.008':<20}")
    print(f"{'Tempo M√©dio':<25} {'2s':<20} {'6s':<20}")
    print(f"{'Provedores':<25} {'1':<20} {'3-4':<20}")
    print(f"{'Qualidade':<25} {'Boa':<20} {'Excelente':<20}")
    
    print("\nüéØ VANTAGENS E DESVANTAGENS")
    print("=" * 60)
    
    print("‚úÖ SISTEMA ATUAL (Uma API):")
    print("  + Mais r√°pido (1 chamada)")
    print("  + Menor custo (5-8x mais barato)")
    print("  + Mais simples de implementar")
    print("  + Menor lat√™ncia")
    print("  - Limitado √† especialidade de um modelo")
    print("  - Qualidade dependente de um √∫nico provedor")
    
    print("\n‚úÖ SISTEMA H√çBRIDO (M√∫ltiplas APIs):")
    print("  + Combina especialidades de diferentes modelos")
    print("  + Maior qualidade e profundidade")
    print("  + Cada etapa usa o melhor modelo especializado")
    print("  + Mais robusto (fallback entre provedores)")
    print("  + Respostas mais completas e precisas")
    print("  - Mais lento (3-4x mais tempo)")
    print("  - Maior custo (5-8x mais caro)")
    print("  - Mais complexo de implementar")

if __name__ == "__main__":
    comparar_sistemas() 