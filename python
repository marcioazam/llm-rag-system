#!/usr/bin/env python3
"""
Script para configurar e testar o sistema RAG multi-modelo
Otimizado para: i5 8gen, 20GB RAM, MX150
"""

import subprocess
import sys
import os
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn

console = Console()

# Modelos recomendados com suas caracter√≠sticas
RECOMMENDED_MODELS = {
    'llama3.1:8b-instruct-q4_K_M': {
        'size': '4.7GB',
        'purpose': 'Explica√ß√µes gerais e documenta√ß√£o',
        'required': True
    },
    'codellama:7b-instruct': {
        'size': '3.8GB',
        'purpose': 'Gera√ß√£o de c√≥digo',
        'required': True
    },
    'mistral:7b-instruct-q4_0': {
        'size': '4.1GB',
        'purpose': 'Arquitetura e design patterns',
        'required': False
    },
    'sqlcoder:7b-q4_0': {
        'size': '4.0GB',
        'purpose': 'Queries SQL complexas',
        'required': False
    },
    'phi:2.7b': {
        'size': '1.6GB',
        'purpose': 'Respostas r√°pidas',
        'required': False
    }
}

def check_system_resources():
    """Verifica recursos do sistema"""
    console.print(Panel.fit("üîç Verificando Recursos do Sistema", style="bold blue"))
    
    # Verifica mem√≥ria
    try:
        import psutil
        mem = psutil.virtual_memory()
        console.print(f"üíæ RAM Total: {mem.total / (1024**3):.1f}GB")
        console.print(f"üíæ RAM Dispon√≠vel: {mem.available / (1024**3):.1f}GB")
        
        if mem.available < 8 * (1024**3):
            console.print("[yellow]‚ö†Ô∏è  Recomenda-se ter pelo menos 8GB livres[/yellow]")
    except ImportError:
        console.print("[yellow]psutil n√£o instalado - instale com: pip install psutil[/yellow]")
    
    # Verifica GPU (MX150)
    console.print("\nüéÆ GPU: NVIDIA MX150 (2GB VRAM)")
    console.print("[dim]Nota: Modelos rodar√£o principalmente na CPU[/dim]")

def check_ollama_installation():
    """Verifica se Ollama est√° instalado"""
    try:
        result = subprocess.run(['ollama', '--version'], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            console.print("‚úÖ Ollama est√° instalado")
            return True
    except FileNotFoundError:
        pass
    
    console.print("[red]‚ùå Ollama n√£o est√° instalado![/red]")
    console.print("Instale com: curl -fsSL https://ollama.com/install.sh | sh")
    return False

def list_installed_models():
    """Lista modelos j√° instalados"""
    try:
        result = subprocess.run(['ollama', 'list'], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            return result.stdout
    except:
        pass
    return ""

def check_and_install_models():
    """Verifica e sugere instala√ß√£o de modelos"""
    console.print("\n" + Panel.fit("üì¶ Verificando Modelos LLM", style="bold blue"))
    
    installed = list_installed_models()
    
    table = Table(title="Status dos Modelos")
    table.add_column("Modelo", style="cyan")
    table.add_column("Tamanho", style="magenta")
    table.add_column("Prop√≥sito", style="yellow")
    table.add_column("Status", style="green")
    table.add_column("A√ß√£o", style="blue")
    
    total_size = 0
    to_install = []
    
    for model, info in RECOMMENDED_MODELS.items():
        model_base = model.split(':')[0]
        is_installed = model_base in installed
        
        status = "‚úÖ Instalado" if is_installed else "‚ùå N√£o instalado"
        action = "-" if is_installed else f"ollama pull {model}"
        
        if not is_installed:
            if info['required']:
                to_install.append((model, info, True))
            else:
                to_install.append((model, info, False))
            total_size += float(info['size'].replace('GB', ''))
        
        table.add_row(
            model,
            info['size'],
            info['purpose'],
            status,
            action
        )
    
    console.print(table)
    
    if to_install:
        console.print(f"\nüíΩ Espa√ßo necess√°rio: ~{total_size:.1f}GB")
        console.print(f"‚è±Ô∏è  Tempo estimado: {int(total_size * 3)} minutos\n")
        
        # Modelos obrigat√≥rios
        required = [m for m in to_install if m[2]]
        optional = [m for m in to_install if not m[2]]
        
        if required:
            console.print("[bold red]Modelos Obrigat√≥rios:[/bold red]")
            for model, info, _ in required:
                console.print(f"  ‚Ä¢ {model} - {info['purpose']}")
        
        if optional:
            console.print("\n[bold yellow]Modelos Opcionais (Recomendados):[/bold yellow]")
            for model, info, _ in optional:
                console.print(f"  ‚Ä¢ {model} - {info['purpose']}")
        
        if console.input("\nü§î Deseja instalar os modelos? [s/N]: ").lower() == 's':
            install_models(to_install)

def install_models(models_to_install):
    """Instala os modelos selecionados"""
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console
    ) as progress:
        
        for model, info, required in models_to_install:
            if not required:
                if console.input(f"\nInstalar {model}? [s/N]: ").lower() != 's':
                    continue
            
            task = progress.add_task(f"Baixando {model}...", total=None)
            
            try:
                result = subprocess.run(
                    ['ollama', 'pull', model],
                    capture_output=True,
                    text=True
                )
                
                progress.remove_task(task)
                
                if result.returncode == 0:
                    console.print(f"‚úÖ {model} instalado com sucesso!")
                else:
                    console.print(f"‚ùå Erro ao instalar {model}: {result.stderr}")
                    
            except Exception as e:
                progress.remove_task(task)
                console.print(f"‚ùå Erro: {str(e)}")

def create_model_config():
    """Cria arquivo de configura√ß√£o para o sistema"""
    config = """# Configura√ß√£o do Sistema RAG Multi-Modelo
# Otimizado para: i5 8gen, 20GB RAM, MX150

MODELS:
  general:
    name: llama3.1:8b-instruct-q4_K_M
    max_tokens: 2048
    temperature: 0.7
    
  code:
    name: codellama:7b-instruct
    max_tokens: 4096
    temperature: 0.3
    
  architecture:
    name: mistral:7b-instruct-q4_0
    max_tokens: 2048
    temperature: 0.8
    
  sql:
    name: sqlcoder:7b-q4_0
    max_tokens: 1024
    temperature: 0.1
    
  fast:
    name: phi:2.7b
    max_tokens: 512
    temperature: 0.5

PERFORMANCE:
  max_concurrent_models: 2  # M√°ximo de modelos rodando simultaneamente
  cpu_threads: 6  # Threads para CPU (i5 8gen tem 4 cores/8 threads)
  use_gpu: false  # MX150 tem pouca VRAM, melhor usar CPU
  
MEMORY:
  model_cache_size: 8192  # MB para cache de modelos
  chunk_size: 512  # Tamanho dos chunks de texto
  max_context: 4096  # Contexto m√°ximo
"""
    
    config_path = "rag_config.yaml"
    with open(config_path, 'w') as f:
        f.write(config)
    
    console.print(f"\nüìÑ Arquivo de configura√ß√£o criado: {config_path}")

def test_multimodel_system():
    """Testa o sistema multi-modelo"""
    console.print("\n" + Panel.fit("üß™ Testando Sistema Multi-Modelo", style="bold green"))
    
    # Adiciona o path do src
    sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))
    
    try:
        from models.model_router import AdvancedModelRouter
        
        router = AdvancedModelRouter()
        status = router.get_model_status()
        
        console.print("\n[bold]Modelos Dispon√≠veis:[/bold]")
        for key, info in status['available'].items():
            console.print(f"  ‚úÖ {key}: {info['name']}")
            console.print(f"     Tarefas: {', '.join(info['tasks'])}")
        
        if status['missing']:
            console.print("\n[bold]Modelos N√£o Encontrados:[/bold]")
            for key, info in status['missing'].items():
                console.print(f"  ‚ùå {key}: {info['name']}")
        
        # Teste r√°pido
        if len(status['available']) >= 2:
            console.print("\n[bold]Executando teste r√°pido...[/bold]")
            test_query = "Como implementar cache em uma API REST?"
            
            result = router.generate_advanced_response(
                query=test_query,
                context="",
                retrieved_docs=["APIs REST devem implementar cache para melhor performance"]
            )
            
            console.print(f"\nModelos usados: {', '.join(result['models_used'])}")
            console.print(f"Tarefas realizadas: {', '.join(result['tasks_performed'])}")
            console.print("\n‚úÖ Sistema multi-modelo funcionando!")
            
    except ImportError:
        console.print("[red]‚ùå Erro ao importar m√≥dulos. Verifique a instala√ß√£o.[/red]")
    except Exception as e:
        console.print(f"[red]‚ùå Erro no teste: {str(e)}[/red]")

def show_optimization_tips():
    """Mostra dicas de otimiza√ß√£o para o hardware"""
    tips = """
üöÄ Dicas de Otimiza√ß√£o para seu Hardware:

1. **Gerenciamento de Mem√≥ria**:
   - Rode apenas 1-2 modelos por vez
   - Use `ollama stop` para liberar mem√≥ria
   - Configure swap de 8-10GB para seguran√ßa

2. **Performance da CPU**:
   - Configure CPU para modo performance:
     `sudo cpupower frequency-set -g performance`
   - Use 6 threads para melhor balan√ßo

3. **Modelos Recomendados por Uso**:
   - Desenvolvimento geral: Llama3.1 + CodeLlama
   - SQL intensivo: Adicione SQLCoder
   - Respostas r√°pidas: Adicione Phi-2

4. **Otimiza√ß√µes do Sistema**:
   ```bash
   # Aumentar limites de mem√≥ria
   sudo sysctl -w vm.max_map_count=262144
   
   # Desabilitar swap aggressiveness
   sudo sysctl -w vm.swappiness=10
   ```

5. **Monitoramento**:
   - Use `htop` para monitorar CPU/RAM
   - Use `ollama ps` para ver modelos ativos
"""
    
    console.print(Panel(tips, title="üí° Otimiza√ß√µes", style="blue"))

def main():
    """Fun√ß√£o principal"""
    console.print(Panel.fit(
        "ü§ñ Setup do Sistema RAG Multi-Modelo\n" +
        "Otimizado para: Intel i5 8¬™ Gen, 20GB RAM, MX150",
        style="bold magenta"
    ))
    
    # 1. Verifica recursos
    check_system_resources()
    
    # 2. Verifica Ollama
    if not check_ollama_installation():
        return
    
    # 3. Verifica e instala modelos
    check_and_install_models()
    
    # 4. Cria configura√ß√£o
    if console.input("\nüìù Criar arquivo de configura√ß√£o? [s/N]: ").lower() == 's':
        create_model_config()
    
    # 5. Testa sistema
    if console.input("\nüß™ Testar sistema multi-modelo? [s/N]: ").lower() == 's':
        test_multimodel_system()
    
    # 6. Mostra dicas
    if console.input("\nüí° Ver dicas de otimiza√ß√£o? [s/N]: ").lower() == 's':
        show_optimization_tips()
    
    console.print("\n‚úÖ Setup conclu√≠do!")

if __name__ == "__main__":
    main()
