"""
Exemplo de uso do Enhanced Semantic Chunker
Demonstra as melhorias incorporadas da proposta original
"""

import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.chunking.semantic_chunker_enhanced import EnhancedSemanticChunker, create_semantic_chunker

def exemplo_basico():
    """Exemplo b√°sico de uso do Enhanced Semantic Chunker"""
    
    # Texto de exemplo em portugu√™s
    texto = """
    O processamento de linguagem natural √© uma √°rea fascinante da intelig√™ncia artificial. 
    Ela envolve o desenvolvimento de algoritmos capazes de compreender e processar textos humanos.
    
    Uma das aplica√ß√µes mais importantes √© o chunking sem√¢ntico. Esta t√©cnica divide documentos 
    em segmentos coerentes baseados no significado. Diferente do chunking simples por tamanho,
    o chunking sem√¢ntico preserva a coes√£o tem√°tica.
    
    Os modelos de embedding como BERT e sentence-transformers revolucionaram esta √°rea.
    Eles conseguem capturar rela√ß√µes sem√¢nticas complexas entre palavras e frases.
    Isso permite agrupar conte√∫do relacionado de forma mais inteligente.
    
    As aplica√ß√µes pr√°ticas incluem sistemas de busca, resumo autom√°tico e chatbots.
    Todos esses sistemas se beneficiam de uma segmenta√ß√£o mais precisa do texto.
    """
    
    print("üöÄ Enhanced Semantic Chunker - Exemplo B√°sico\n")
    
    # Criar chunker aprimorado
    chunker = EnhancedSemanticChunker(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        similarity_threshold=0.6,
        max_chunk_size=300,
        language="portuguese",
        use_centroids=True
    )
    
    # Processar texto
    chunks = chunker.chunk(texto, {"document_id": "exemplo_1", "source": "manual"})
    
    print(f"üìÑ Texto original: {len(texto)} caracteres")
    print(f"üî® Chunks gerados: {len(chunks)}")
    print("=" * 50)
    
    for i, chunk in enumerate(chunks, 1):
        print(f"\nüì¶ Chunk {i}:")
        print(f"   Tamanho: {len(chunk.content)} caracteres")
        print(f"   Senten√ßas: {chunk.metadata.get('sentence_count', 'N/A')}")
        print(f"   Conte√∫do: {chunk.content[:100]}...")
        print(f"   ID: {chunk.chunk_id[:8]}...")

def exemplo_comparativo():
    """Compara o Enhanced com implementa√ß√£o original"""
    
    print("\nüîÑ Compara√ß√£o: Enhanced vs Original\n")
    
    texto = """
    Python √© uma linguagem de programa√ß√£o vers√°til. √â amplamente usada em ci√™ncia de dados.
    Machine learning tornou-se muito popular recentemente. Bibliotecas como scikit-learn facilitam o desenvolvimento.
    O processamento de texto √© uma aplica√ß√£o comum. NLTK e spaCy s√£o ferramentas populares para isso.
    """
    
    # Enhanced Chunker
    enhanced = EnhancedSemanticChunker(
        similarity_threshold=0.5,
        max_chunk_size=150
    )
    
    chunks_enhanced = enhanced.chunk(texto, {"source": "teste"})
    
    print("üÜï Enhanced Semantic Chunker:")
    for i, chunk in enumerate(chunks_enhanced, 1):
        print(f"   Chunk {i}: {len(chunk.content)} chars - {chunk.content[:50]}...")
    
    # Usando m√©todo compat√≠vel com proposta original
    print("\nüîÑ M√©todo compat√≠vel com proposta original:")
    chunks_simples = enhanced.semantic_chunking(texto, max_chunk_size=150)
    
    for i, chunk in enumerate(chunks_simples, 1):
        print(f"   Chunk {i}: {len(chunk)} chars - {chunk[:50]}...")

def exemplo_configuracoes_avancadas():
    """Demonstra configura√ß√µes avan√ßadas"""
    
    print("\n‚öôÔ∏è Configura√ß√µes Avan√ßadas\n")
    
    texto = """
    Artificial intelligence has revolutionized many industries. Machine learning algorithms can now process vast amounts of data.
    Natural language processing is particularly exciting. It enables computers to understand human language.
    Deep learning models like transformers have shown remarkable results. They can generate text that is almost indistinguishable from human writing.
    """
    
    # Configura√ß√µes diferentes
    configs = [
        {"name": "Conservador", "threshold": 0.8, "centroids": True},
        {"name": "Balanceado", "threshold": 0.6, "centroids": True},
        {"name": "Agressivo", "threshold": 0.4, "centroids": False}
    ]
    
    for config in configs:
        print(f"\nüìã {config['name']} (threshold={config['threshold']}, centroids={config['centroids']}):")
        
        chunker = EnhancedSemanticChunker(
            similarity_threshold=config['threshold'],
            max_chunk_size=200,
            language="english",
            use_centroids=config['centroids']
        )
        
        chunks = chunker.chunk(texto, {"config": config['name']})
        
        print(f"   Chunks gerados: {len(chunks)}")
        for i, chunk in enumerate(chunks, 1):
            print(f"   Chunk {i}: {len(chunk.content)} chars")

def exemplo_compatibilidade():
    """Demonstra compatibilidade com interface proposta"""
    
    print("\nüîó Compatibilidade com Interface Original\n")
    
    # Usando fun√ß√£o de conveni√™ncia (como na proposta)
    chunker = create_semantic_chunker(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        similarity_threshold=0.6
    )
    
    texto = "Esta √© uma senten√ßa. Esta √© outra senten√ßa relacionada. Esta √© uma senten√ßa diferente sobre outro t√≥pico."
    
    # M√©todo compat√≠vel com a proposta original
    chunks = chunker.semantic_chunking(texto, max_chunk_size=512)
    
    print(f"üìÑ Chunks usando interface compat√≠vel:")
    for i, chunk in enumerate(chunks, 1):
        print(f"   {i}: {chunk}")

if __name__ == "__main__":
    exemplo_basico()
    exemplo_comparativo()
    exemplo_configuracoes_avancadas()
    exemplo_compatibilidade()
    
    print("\n" + "="*60)
    print("‚úÖ Enhanced Semantic Chunker oferece:")
    print("   ‚Ä¢ NLTK para divis√£o de senten√ßas mais precisa")
    print("   ‚Ä¢ C√°lculo de centroides para melhor representa√ß√£o")
    print("   ‚Ä¢ Suporte nativo ao portugu√™s")
    print("   ‚Ä¢ Cache LRU para performance")
    print("   ‚Ä¢ Metadados ricos e UUIDs")
    print("   ‚Ä¢ Compatibilidade com sistema existente")
    print("   ‚Ä¢ Interface compat√≠vel com proposta original") 