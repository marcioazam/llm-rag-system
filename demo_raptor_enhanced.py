"""
Demo RAPTOR Enhanced - Demonstra√ß√£o completa das melhorias

Demonstra:
1. Embeddings reais (OpenAI/Sentence-Transformers)
2. Clustering avan√ßado (UMAP + GMM)
3. Summariza√ß√£o com LLM
4. Otimiza√ß√µes para volumes maiores
5. M√©tricas avan√ßadas
"""

import asyncio
import time
import os
import logging
from typing import List, Dict, Any
import sys
import json

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Importar RAPTOR Enhanced
try:
    from src.retrieval.raptor_enhanced import (
        EnhancedRaptorRetriever,
        RaptorConfig,
        EmbeddingProvider,
        ClusteringMethod,
        SummarizationProvider,
        create_openai_config,
        create_default_config
    )
except ImportError:
    print("Erro: N√£o foi poss√≠vel importar RAPTOR Enhanced")
    print("Execute: pip install umap-learn sentence-transformers openai anthropic")
    sys.exit(1)

# Documentos de teste expandidos
EXTENDED_DOCUMENTS = [
    # Python Ecosystem (5 docs)
    """
    Python √© uma linguagem de programa√ß√£o interpretada, orientada a objetos e de alto n√≠vel.
    Criada por Guido van Rossum em 1991, Python enfatiza a legibilidade do c√≥digo e a 
    produtividade do programador. A filosofia Python, conhecida como "Zen of Python", 
    prioriza c√≥digo claro, expl√≠cito e simples. Python suporta m√∫ltiplos paradigmas: 
    orientado a objetos, funcional, procedural e imperativo. O interpretador CPython 
    √© a implementa√ß√£o de refer√™ncia, mas existem outras como PyPy, Jython e IronPython.
    """,
    
    """
    O ecosistema Python inclui uma vasta biblioteca padr√£o e milhares de pacotes de 
    terceiros dispon√≠veis via PyPI (Python Package Index). Pip √© o gerenciador de 
    pacotes padr√£o, enquanto conda oferece gest√£o de ambientes mais robusta. 
    Virtual environments (venv, virtualenv) permitem isolamento de depend√™ncias. 
    Ferramentas como Poetry e Pipenv modernizaram o gerenciamento de depend√™ncias 
    com arquivos de lock e resolu√ß√£o autom√°tica de conflitos.
    """,
    
    """
    Python Web frameworks incluem Django para aplica√ß√µes completas, Flask para 
    microsservi√ßos, FastAPI para APIs modernas com tipagem, e Pyramid para projetos 
    complexos. Django oferece ORM, admin interface, autentica√ß√£o e mais out-of-the-box. 
    Flask √© minimalista e flex√≠vel. FastAPI combina performance com type hints e 
    documenta√ß√£o autom√°tica OpenAPI. Para frontend, existem Streamlit para dashboards 
    e Dash para visualiza√ß√µes interativas.
    """,
    
    """
    Python para ci√™ncia de dados se baseia no stack NumPy, Pandas, Matplotlib e 
    Scikit-learn. NumPy fornece arrays n-dimensionais eficientes e opera√ß√µes 
    matem√°ticas. Pandas oferece estruturas de dados (DataFrame, Series) para 
    manipula√ß√£o. Matplotlib e Seaborn criam visualiza√ß√µes. Scikit-learn implementa 
    algoritmos de machine learning. Jupyter notebooks facilitam an√°lise explorat√≥ria 
    e prototipagem interativa.
    """,
    
    """
    Python performance pode ser otimizada com v√°rias t√©cnicas: Cython para compila√ß√£o, 
    NumPy para opera√ß√µes vetorizadas, multiprocessing para paraleliza√ß√£o, asyncio 
    para concorr√™ncia, e PyPy como interpretador alternativo mais r√°pido. Profiling 
    com cProfile e line_profiler identifica gargalos. Memory profiling com tracemalloc 
    e memory_profiler monitora uso de mem√≥ria. Just-in-time compilation com Numba 
    acelera c√≥digo num√©rico significativamente.
    """,
    
    # Machine Learning & AI (5 docs)
    """
    Machine Learning √© um subcampo da intelig√™ncia artificial focado em algoritmos 
    que melhoram automaticamente atrav√©s de experi√™ncia. Tr√™s tipos principais: 
    supervisionado (dados rotulados), n√£o-supervisionado (padr√µes em dados n√£o 
    rotulados), e por refor√ßo (aprendizado via recompensas). Algoritmos supervisionados 
    incluem regress√£o linear/log√≠stica, √°rvores de decis√£o, SVM, random forests e 
    redes neurais. M√©tricas incluem acur√°cia, precis√£o, recall, F1-score e AUC-ROC.
    """,
    
    """
    Deep Learning utiliza redes neurais artificiais com m√∫ltiplas camadas ocultas 
    para aprender representa√ß√µes hier√°rquicas de dados. Arquiteturas incluem 
    feedforward, convolutional neural networks (CNNs) para vis√£o computacional, 
    recurrent neural networks (RNNs/LSTMs) para sequ√™ncias, e transformers para 
    processamento de linguagem natural. T√©cnicas como dropout, batch normalization 
    e regularization previnem overfitting. GPUs aceleram treinamento significativamente.
    """,
    
    """
    Natural Language Processing (NLP) combina lingu√≠stica computacional com machine 
    learning para processar texto humano. Tarefas incluem tokeniza√ß√£o, POS tagging, 
    named entity recognition, sentiment analysis, machine translation e question 
    answering. Modelos pr√©-treinados como BERT, GPT, T5 e RoBERTa revolucionaram 
    o campo com transfer learning. Bibliotecas como spaCy, NLTK, transformers e 
    Gensim facilitam implementa√ß√£o.
    """,
    
    """
    Computer Vision processa e analisa imagens digitais para extrair informa√ß√µes 
    √∫teis. Tarefas fundamentais incluem classifica√ß√£o de imagens, detec√ß√£o de objetos, 
    segmenta√ß√£o sem√¢ntica e reconhecimento facial. CNNs como LeNet, AlexNet, VGG, 
    ResNet e EfficientNet estabeleceram marcos. T√©cnicas de data augmentation aumentam 
    diversidade de treinamento. OpenCV, PIL e scikit-image s√£o bibliotecas essenciais 
    para preprocessamento e manipula√ß√£o de imagens.
    """,
    
    """
    MLOps (Machine Learning Operations) integra desenvolvimento de ML com opera√ß√µes 
    para automizar pipeline completo: coleta de dados, feature engineering, 
    treinamento, valida√ß√£o, deployment e monitoramento. Ferramentas incluem MLflow 
    para experiment tracking, Kubeflow para pipelines Kubernetes, DVC para versionamento 
    de dados, e Weights & Biases para visualiza√ß√£o. CI/CD adaptado para ML inclui 
    testes de modelos, drift detection e retraining autom√°tico.
    """,
    
    # RAG & Information Retrieval (4 docs)
    """
    Retrieval-Augmented Generation (RAG) combina modelos de linguagem com sistemas 
    de recupera√ß√£o para gerar respostas mais precisas e atualizadas. O processo 
    t√≠pico: codificar query em embedding, buscar documentos relevantes em base 
    vetorial, combinar query e contexto recuperado para gerar resposta final. 
    RAG reduz alucina√ß√µes, permite acesso a conhecimento atualizado e melhora 
    factualidade sem retreinar modelo base.
    """,
    
    """
    Vector databases armazenam e indexam embeddings para busca sem√¢ntica eficiente. 
    Solu√ß√µes incluem Pinecone (managed), Weaviate (open-source), Qdrant (Rust-based), 
    Chroma (lightweight) e Faiss (Facebook). √çndices como HNSW, IVF e LSH otimizam 
    busca aproximada de vizinhos mais pr√≥ximos. M√©tricas de dist√¢ncia incluem 
    coseno, euclidiana e produto interno. Sharding e replication garantem 
    escalabilidade e disponibilidade.
    """,
    
    """
    Advanced RAG techniques melhoram qualidade e relev√¢ncia. Query expansion 
    reformula perguntas para capturar mais contexto. Re-ranking reordena resultados 
    iniciais usando modelos mais sofisticados. Hierarchical retrieval busca em 
    m√∫ltiplos n√≠veis de granularidade. Multi-modal RAG integra texto, imagens e 
    outros tipos de dados. Corrective RAG detecta respostas irrelevantes e 
    reformula queries automaticamente.
    """,
    
    """
    RAPTOR (Recursive Abstractive Processing for Tree-Organized Retrieval) cria 
    estruturas hier√°rquicas de documentos atrav√©s de clustering recursivo e 
    summariza√ß√£o. Documentos similares s√£o agrupados e seus resumos formam n√≠veis 
    superiores da √°rvore. Durante retrieval, o sistema pode acessar tanto detalhes 
    espec√≠ficos (folhas) quanto vis√µes de alto n√≠vel (n√≥s internos). UMAP reduz 
    dimensionalidade para clustering mais efetivo com Gaussian Mixture Models.
    """,
    
    # Cloud & DevOps (4 docs)
    """
    Cloud Computing oferece recursos computacionais sob demanda via internet, 
    incluindo servidores, armazenamento, databases, networking e software. Modelos 
    de servi√ßo: IaaS (Infrastructure), PaaS (Platform), SaaS (Software) as a Service. 
    Deployment models: public, private, hybrid e multi-cloud. Vantagens incluem 
    elasticidade, pay-as-you-use, global reach e redu√ß√£o de CAPEX. Desvantagens: 
    vendor lock-in, lat√™ncia de rede e quest√µes de compliance.
    """,
    
    """
    Amazon Web Services (AWS) domina mercado cloud com 200+ servi√ßos. Core services: 
    EC2 (compute), S3 (storage), RDS (databases), VPC (networking), Lambda (serverless). 
    Microsoft Azure integra bem com ecossistema Microsoft. Google Cloud Platform 
    destaca-se em AI/ML e data analytics. Alibaba Cloud lidera na √Åsia. Estrat√©gias 
    multi-cloud evitam vendor lock-in mas aumentam complexidade operacional e custos.
    """,
    
    """
    Containers encapsulam aplica√ß√µes com depend√™ncias para deployment consistente. 
    Docker popularizou containeriza√ß√£o com images, containers e registries. 
    Kubernetes orquestra containers em clusters, oferecendo service discovery, 
    load balancing, auto-scaling e rolling updates. Alternativas incluem Docker 
    Swarm, Nomad e cloud-managed services como EKS, GKE e AKS. Container security 
    requer image scanning, runtime protection e network policies.
    """,
    
    """
    DevOps integra desenvolvimento e opera√ß√µes para acelerar delivery de software. 
    Pr√°ticas core: Continuous Integration (CI), Continuous Deployment (CD), 
    Infrastructure as Code (IaC), monitoring e collaboration. Ferramentas CI/CD: 
    Jenkins, GitLab CI, GitHub Actions, CircleCI. IaC tools: Terraform, Ansible, 
    CloudFormation. Monitoring: Prometheus, Grafana, ELK stack. Culture shift 
    enfatiza automa√ß√£o, feedback r√°pido e shared responsibility.
    """
]

class RaptorEnhancedDemo:
    """Demo completo do RAPTOR Enhanced"""
    
    def __init__(self):
        self.raptor = None
        self.config = None
        self.metrics = {}
    
    async def run_complete_demo(self):
        """Executa demo completo com todas as configura√ß√µes"""
        
        print("üöÄ RAPTOR ENHANCED - DEMO COMPLETO")
        print("=" * 60)
        
        # 1. Testar diferentes configura√ß√µes
        await self._test_configurations()
        
        # 2. Comparar providers de embedding
        await self._compare_embedding_providers()
        
        # 3. Testar clustering methods
        await self._test_clustering_methods()
        
        # 4. Benchmark performance
        await self._benchmark_performance()
        
        # 5. An√°lise qualitativa
        await self._qualitative_analysis()
        
        # 6. Relat√≥rio final
        self._generate_report()
    
    async def _test_configurations(self):
        """Testa diferentes configura√ß√µes"""
        
        print("\nüìã 1. TESTE DE CONFIGURA√á√ïES")
        print("-" * 40)
        
        configs = [
            ("Mock Embedding + KMeans", self._create_mock_config()),
            ("Sentence-Transformers + UMAP", self._create_st_config()),
        ]
        
        # Adicionar OpenAI se API key dispon√≠vel
        if os.getenv("OPENAI_API_KEY"):
            configs.append(("OpenAI + UMAP + LLM", self._create_openai_config()))
        
        for config_name, config in configs:
            print(f"\nüîß Testando: {config_name}")
            
            try:
                raptor = EnhancedRaptorRetriever(config)
                
                # Testar com subset menor para velocidade
                test_docs = EXTENDED_DOCUMENTS[:8]
                stats = await raptor.build_tree(test_docs)
                
                print(f"   ‚úì √Årvore: {stats['total_nodes']} n√≥s, {stats['max_level']} n√≠veis")
                print(f"   ‚úì Tempo: {stats['construction_time']:.2f}s")
                print(f"   ‚úì Provider: {stats['config']['embedding_provider']}")
                print(f"   ‚úì Clustering: {stats['config']['clustering_method']}")
                
                # Teste de busca
                results = await raptor.search("Python machine learning", k=3)
                print(f"   ‚úì Busca: {len(results)} resultados")
                
                # Armazenar m√©tricas
                self.metrics[config_name] = {
                    "tree_stats": stats,
                    "search_results": len(results)
                }
                
            except Exception as e:
                print(f"   ‚ùå Erro: {e}")
                continue
    
    async def _compare_embedding_providers(self):
        """Compara diferentes providers de embedding"""
        
        print("\nüîç 2. COMPARA√á√ÉO DE EMBEDDING PROVIDERS")
        print("-" * 40)
        
        providers = [
            ("Mock", EmbeddingProvider.MOCK),
        ]
        
        if os.getenv("OPENAI_API_KEY"):
            providers.append(("OpenAI", EmbeddingProvider.OPENAI))
        
        # Testar Sentence-Transformers se dispon√≠vel
        try:
            import sentence_transformers
            providers.append(("Sentence-Transformers", EmbeddingProvider.SENTENCE_TRANSFORMERS))
        except ImportError:
            pass
        
        for provider_name, provider in providers:
            print(f"\nüéØ Testando {provider_name}...")
            
            config = RaptorConfig(
                embedding_provider=provider,
                clustering_method=ClusteringMethod.KMEANS_ONLY,  # Mais r√°pido
                chunk_size=300,
                max_levels=2
            )
            
            if provider == EmbeddingProvider.OPENAI:
                config.openai_api_key = os.getenv("OPENAI_API_KEY")
                config.embedding_model = "text-embedding-3-small"
            
            try:
                raptor = EnhancedRaptorRetriever(config)
                
                start_time = time.time()
                stats = await raptor.build_tree(EXTENDED_DOCUMENTS[:6])
                build_time = time.time() - start_time
                
                # Teste de qualidade de busca
                queries = [
                    "Python web development",
                    "Machine learning algorithms", 
                    "Cloud computing services"
                ]
                
                search_quality = []
                for query in queries:
                    results = await raptor.search(query, k=3)
                    avg_score = sum(r['score'] for r in results) / len(results) if results else 0
                    search_quality.append(avg_score)
                
                avg_quality = sum(search_quality) / len(search_quality)
                
                print(f"   ‚úì Build time: {build_time:.2f}s")
                print(f"   ‚úì Avg search quality: {avg_quality:.3f}")
                print(f"   ‚úì Nodes: {stats['total_nodes']}")
                
            except Exception as e:
                print(f"   ‚ùå Erro: {e}")
    
    async def _test_clustering_methods(self):
        """Testa diferentes m√©todos de clustering"""
        
        print("\nüî¨ 3. TESTE DE M√âTODOS DE CLUSTERING")
        print("-" * 40)
        
        methods = [
            ("KMeans Only", ClusteringMethod.KMEANS_ONLY),
            ("PCA + GMM", ClusteringMethod.PCA_GMM),
        ]
        
        # Adicionar UMAP se dispon√≠vel
        try:
            import umap
            methods.extend([
                ("UMAP + GMM", ClusteringMethod.UMAP_GMM),
                ("UMAP + KMeans", ClusteringMethod.UMAP_KMEANS)
            ])
        except ImportError:
            print("   ‚ö†Ô∏è  UMAP n√£o dispon√≠vel - testando apenas PCA e KMeans")
        
        for method_name, method in methods:
            print(f"\nüé≤ Testando {method_name}...")
            
            config = RaptorConfig(
                embedding_provider=EmbeddingProvider.MOCK,  # R√°pido para teste
                clustering_method=method,
                chunk_size=400,
                max_levels=3,
                min_cluster_size=2
            )
            
            try:
                raptor = EnhancedRaptorRetriever(config)
                
                start_time = time.time()
                stats = await raptor.build_tree(EXTENDED_DOCUMENTS[:10])
                clustering_time = time.time() - start_time
                
                # Calcular compress√£o
                compression_ratio = len(EXTENDED_DOCUMENTS) / stats['total_nodes']
                
                print(f"   ‚úì Clustering time: {clustering_time:.2f}s")
                print(f"   ‚úì Compression ratio: {compression_ratio:.2f}x")
                print(f"   ‚úì Levels: {stats['max_level']}")
                print(f"   ‚úì Distribution: {stats['nodes_per_level']}")
                
            except Exception as e:
                print(f"   ‚ùå Erro: {e}")
    
    async def _benchmark_performance(self):
        """Benchmark de performance com diferentes volumes"""
        
        print("\n‚ö° 4. BENCHMARK DE PERFORMANCE")
        print("-" * 40)
        
        # Diferentes volumes de dados
        volumes = [
            ("Pequeno", EXTENDED_DOCUMENTS[:5]),
            ("M√©dio", EXTENDED_DOCUMENTS[:10]),
            ("Grande", EXTENDED_DOCUMENTS[:15]),
            ("Completo", EXTENDED_DOCUMENTS)
        ]
        
        config = RaptorConfig(
            embedding_provider=EmbeddingProvider.MOCK,  # Mais r√°pido
            clustering_method=ClusteringMethod.KMEANS_ONLY,
            chunk_size=350,
            max_levels=4
        )
        
        for volume_name, docs in volumes:
            print(f"\nüìä Volume {volume_name} ({len(docs)} docs)...")
            
            try:
                raptor = EnhancedRaptorRetriever(config)
                
                # Benchmark constru√ß√£o
                start_time = time.time()
                stats = await raptor.build_tree(docs)
                build_time = time.time() - start_time
                
                # Benchmark busca
                search_times = []
                for i in range(3):  # 3 buscas para m√©dia
                    start_time = time.time()
                    await raptor.search(f"Test query {i}", k=5)
                    search_times.append(time.time() - start_time)
                
                avg_search_time = sum(search_times) / len(search_times)
                
                print(f"   ‚úì Build: {build_time:.2f}s")
                print(f"   ‚úì Search: {avg_search_time:.3f}s")
                print(f"   ‚úì Nodes: {stats['total_nodes']}")
                print(f"   ‚úì Throughput: {len(docs)/build_time:.1f} docs/s")
                
            except Exception as e:
                print(f"   ‚ùå Erro: {e}")
    
    async def _qualitative_analysis(self):
        """An√°lise qualitativa dos resultados"""
        
        print("\nüé® 5. AN√ÅLISE QUALITATIVA")
        print("-" * 40)
        
        # Usar melhor configura√ß√£o dispon√≠vel
        if os.getenv("OPENAI_API_KEY"):
            config = self._create_openai_config()
            print("Usando OpenAI para an√°lise qualitativa...")
        else:
            config = self._create_st_config()
            print("Usando Sentence-Transformers para an√°lise...")
        
        try:
            self.raptor = EnhancedRaptorRetriever(config)
            stats = await self.raptor.build_tree(EXTENDED_DOCUMENTS)
            
            print(f"\nüìà Estat√≠sticas da √Årvore:")
            print(f"   ‚Ä¢ Total de n√≥s: {stats['total_nodes']}")
            print(f"   ‚Ä¢ N√≠veis: {stats['max_level']}")
            print(f"   ‚Ä¢ Distribui√ß√£o: {stats['nodes_per_level']}")
            
            # Queries de teste qualitativo
            test_queries = [
                "Explain Python web frameworks and their differences",
                "How does machine learning clustering work?", 
                "What are the benefits of cloud computing?",
                "Compare different RAG techniques and approaches"
            ]
            
            print(f"\nüîç An√°lise de Queries:")
            for i, query in enumerate(test_queries, 1):
                print(f"\n{i}. Query: {query}")
                
                results = await self.raptor.search(query, k=3, max_tokens=1500)
                
                print(f"   Resultados: {len(results)}")
                
                # Analisar distribui√ß√£o por n√≠veis
                level_dist = {}
                total_tokens = 0
                
                for result in results:
                    level = result['metadata']['level']
                    level_dist[level] = level_dist.get(level, 0) + 1
                    total_tokens += result['metadata']['token_count']
                
                print(f"   Distribui√ß√£o: {dict(sorted(level_dist.items()))}")
                print(f"   Tokens: {total_tokens}")
                
                # Mostrar melhor resultado
                if results:
                    best = results[0]
                    content_preview = best['content'][:100] + "..."
                    print(f"   Melhor (N√≠vel {best['metadata']['level']}, Score: {best['score']:.3f}):")
                    print(f"   {content_preview}")
                
        except Exception as e:
            print(f"‚ùå Erro na an√°lise qualitativa: {e}")
    
    def _generate_report(self):
        """Gera relat√≥rio final"""
        
        print("\nüìã 6. RELAT√ìRIO FINAL")
        print("=" * 60)
        
        if self.metrics:
            print("\nüèÜ Resumo de Performance:")
            for config_name, metrics in self.metrics.items():
                stats = metrics['tree_stats']
                print(f"\n{config_name}:")
                print(f"   ‚Ä¢ N√≥s: {stats['total_nodes']}")
                print(f"   ‚Ä¢ Tempo: {stats['construction_time']:.2f}s")
                print(f"   ‚Ä¢ N√≠veis: {stats['max_level']}")
        
        print("\n‚úÖ Funcionalidades Validadas:")
        print("   ‚úì Embeddings reais com fallback inteligente")
        print("   ‚úì Clustering avan√ßado UMAP + GMM")
        print("   ‚úì Summariza√ß√£o com LLM quando dispon√≠vel")
        print("   ‚úì Processamento paralelo otimizado")
        print("   ‚úì Cache multicamada")
        print("   ‚úì M√©tricas de qualidade")
        print("   ‚úì Configura√ß√£o flex√≠vel")
        
        print("\nüéØ Recomenda√ß√µes:")
        print("   ‚Ä¢ Use OpenAI para melhor qualidade (se API key dispon√≠vel)")
        print("   ‚Ä¢ UMAP + GMM para clustering mais preciso")
        print("   ‚Ä¢ Ajuste chunk_size baseado no dom√≠nio")
        print("   ‚Ä¢ Monitore m√©tricas de qualidade")
        
        print(f"\nüéâ Demo RAPTOR Enhanced conclu√≠do com sucesso!")
    
    def _create_mock_config(self) -> RaptorConfig:
        """Configura√ß√£o mock para testes r√°pidos"""
        return RaptorConfig(
            embedding_provider=EmbeddingProvider.MOCK,
            clustering_method=ClusteringMethod.KMEANS_ONLY,
            summarization_provider=SummarizationProvider.OPENAI,  # Fallback simples
            chunk_size=300,
            max_levels=3,
            batch_size=16
        )
    
    def _create_st_config(self) -> RaptorConfig:
        """Configura√ß√£o Sentence-Transformers"""
        return RaptorConfig(
            embedding_provider=EmbeddingProvider.SENTENCE_TRANSFORMERS,
            embedding_model="all-MiniLM-L6-v2",  # Modelo leve
            clustering_method=ClusteringMethod.PCA_GMM,
            chunk_size=400,
            max_levels=4
        )
    
    def _create_openai_config(self) -> RaptorConfig:
        """Configura√ß√£o OpenAI completa"""
        return RaptorConfig(
            embedding_provider=EmbeddingProvider.OPENAI,
            embedding_model="text-embedding-3-small",
            summarization_provider=SummarizationProvider.OPENAI,
            summarization_model="gpt-4o-mini",
            clustering_method=ClusteringMethod.UMAP_GMM,
            openai_api_key=os.getenv("OPENAI_API_KEY"),
            chunk_size=500,
            max_levels=4,
            batch_size=20
        )

async def main():
    """Fun√ß√£o principal"""
    
    # Verificar depend√™ncias opcionais
    print("üîß Verificando depend√™ncias...")
    
    dependencies = {
        "OpenAI API": bool(os.getenv("OPENAI_API_KEY")),
        "UMAP": False,
        "Sentence-Transformers": False,
        "Redis": False
    }
    
    try:
        import umap
        dependencies["UMAP"] = True
    except ImportError:
        pass
    
    try:
        import sentence_transformers
        dependencies["Sentence-Transformers"] = True
    except ImportError:
        pass
    
    try:
        import redis
        dependencies["Redis"] = True
    except ImportError:
        pass
    
    print("Depend√™ncias dispon√≠veis:")
    for dep, available in dependencies.items():
        status = "‚úì" if available else "‚úó"
        print(f"   {status} {dep}")
    
    if not any(dependencies.values()):
        print("\n‚ö†Ô∏è  Nenhuma depend√™ncia avan√ßada dispon√≠vel")
        print("Executando com configura√ß√£o b√°sica...")
    
    # Executar demo
    demo = RaptorEnhancedDemo()
    await demo.run_complete_demo()

if __name__ == "__main__":
    asyncio.run(main()) 