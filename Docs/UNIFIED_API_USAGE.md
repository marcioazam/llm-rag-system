# ðŸŽ¯ API UNIFICADA: Um Endpoint para Todos

## âœ… **PROBLEMA RESOLVIDO**

**ANTES:** Dois sistemas separados
- `cursor_endpoint.py` (247 linhas) - Endpoints especÃ­ficos para Cursor
- `main.py` (369 linhas) - API geral

**AGORA:** Um sistema unificado
- `main.py` (400+ linhas) - API Ãºnica com otimizaÃ§Ãµes automÃ¡ticas
- âŒ `cursor_endpoint.py` - REMOVIDO

---

## ðŸš€ **COMO USAR**

### **1. ðŸ“± Uso Geral (MCP, aplicaÃ§Ãµes web, etc.)**
```json
POST /query
{
  "question": "Como implementar autenticaÃ§Ã£o JWT?",
  "k": 5,
  "use_hybrid": true
}
```

### **2. ðŸ–¥ï¸ Uso Otimizado para Cursor IDE**
```json
POST /query
{
  "question": "Como usar esta funÃ§Ã£o?",
  "k": 3,
  "context": "def authenticate_user(username, password):\n    # cÃ³digo atual",
  "file_type": ".py",
  "project_context": "Sistema de autenticaÃ§Ã£o Flask",
  "quick_mode": true,
  "max_response_time": 5
}
```

### **3. ðŸ”§ ParÃ¢metros DisponÃ­veis**

| ParÃ¢metro | Tipo | PadrÃ£o | DescriÃ§Ã£o |
|-----------|------|--------|-----------|
| **`question`** | string | - | **ObrigatÃ³rio** - Pergunta principal |
| `k` | int | 5 | NÃºmero de chunks a recuperar |
| `use_hybrid` | bool | true | Usar busca hÃ­brida |
| `llm_only` | bool | false | Usar apenas LLM (sem RAG) |
| `system_prompt` | string | null | Prompt customizado |
| | | | |
| **CURSOR ESPECÃFICOS** | | | |
| `context` | string | null | CÃ³digo atual do arquivo |
| `file_type` | string | null | Tipo de arquivo (.py, .js, etc) |
| `project_context` | string | null | Contexto do projeto |
| `quick_mode` | bool | false | Modo rÃ¡pido (menos chunks) |
| `allow_hybrid` | bool | true | Permitir busca hÃ­brida |
| `max_response_time` | int | 15 | Timeout mÃ¡ximo |

---

## ðŸ§  **INTELIGÃŠNCIA AUTOMÃTICA**

### **DetecÃ§Ã£o AutomÃ¡tica de Contexto**
A API detecta automaticamente se Ã© uma **request do Cursor** baseado nos parÃ¢metros enviados:

```python
# Se request contÃ©m context, file_type ou project_context
# Ativa otimizaÃ§Ãµes para Cursor automaticamente
if request.context or request.file_type or request.project_context:
    # ConstrÃ³i prompt especializado para IDE
    # Ajusta parÃ¢metros para velocidade
    # Adiciona contexto especÃ­fico da linguagem
```

### **OtimizaÃ§Ãµes Ativadas**
- âœ… **System prompt otimizado** para cada linguagem
- âœ… **ReduÃ§Ã£o de K** em modo rÃ¡pido (3 em vez de 5)
- âœ… **Contexto de cÃ³digo** incluÃ­do no prompt
- âœ… **MÃ©tricas de performance** na resposta

---

## ðŸ“Š **EXEMPLOS PRÃTICOS**

### **MCP pode chamar diretamente:**
```python
# tools/rag_query.py para MCP
import httpx

async def rag_query(question: str) -> dict:
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8000/query",
            json={
                "question": question,
                "k": 5,
                "use_hybrid": True
            }
        )
        return response.json()

# Uso no MCP
result = await rag_query("Como implementar cache em Python?")
```

### **Cursor pode usar com contexto:**
```javascript
// Cursor integration
const response = await fetch('http://localhost:8000/query', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    question: "Como melhorar esta funÃ§Ã£o?",
    context: getCurrentFileContent(),
    file_type: getCurrentFileExtension(),
    project_context: getProjectName(),
    quick_mode: true
  })
});
```

### **AplicaÃ§Ã£o web padrÃ£o:**
```python
# cliente.py
import requests

def ask_rag(question: str) -> dict:
    response = requests.post(
        "http://localhost:8000/query",
        json={"question": question}
    )
    return response.json()
```

---

## ðŸŽ¯ **RESPOSTA UNIFICADA**

### **Estrutura PadrÃ£o**
```json
{
  "answer": "Resposta gerada...",
  "sources": [{"content": "...", "metadata": {...}}],
  "model": "openai.gpt4o_mini",
  "provider_used": "openai",
  "processing_time": 2.314,
  "mode": "cursor_optimized",
  "k_used": 3
}
```

### **Campos Adicionais para Cursor**
- `processing_time`: Tempo de processamento em segundos
- `mode`: "cursor_optimized" ou "standard"
- `k_used`: NÃºmero real de chunks usados
- `provider_used`: Provedor LLM utilizado

---

## âš¡ **VANTAGENS DA UNIFICAÃ‡ÃƒO**

### **Para Desenvolvedores**
- âœ… **Um endpoint para tudo** - Menos complexidade
- âœ… **ParÃ¢metros opcionais** - Backward compatibility
- âœ… **OtimizaÃ§Ãµes automÃ¡ticas** - Detecta contexto

### **Para MCP**
- âœ… **IntegraÃ§Ã£o direta** - Apenas `/query`
- âœ… **Sem configuraÃ§Ã£o extra** - Funciona out-of-the-box
- âœ… **Performance padrÃ£o** - Otimizada por padrÃ£o

### **Para Cursor**
- âœ… **OtimizaÃ§Ãµes especÃ­ficas** - Context-aware
- âœ… **Modo rÃ¡pido** - Respostas em 2-5s
- âœ… **Prompts especializados** - Por linguagem

### **Para ManutenÃ§Ã£o**
- âœ… **Menos cÃ³digo** - 247 linhas removidas
- âœ… **Menos bugs** - Um sistema em vez de dois
- âœ… **Mais simples** - Uma API para manter

---

## ðŸ”§ **MIGRAÃ‡ÃƒO**

### **Se vocÃª usava `/cursor/query` antes:**
```diff
- POST /cursor/query
+ POST /query

# Adicionar parÃ¢metros especÃ­ficos:
{
  "question": "sua pergunta",
+ "context": "cÃ³digo atual",
+ "file_type": ".py",
+ "quick_mode": true
}
```

### **Se vocÃª usava `/cursor/quick` antes:**
```diff
- POST /cursor/quick
+ POST /query

# Equivalente:
{
  "question": "sua pergunta",
+ "quick_mode": true,
+ "k": 3
}
```

---

## âœ… **RESULTADO FINAL**

### **API Simplificada:**
- ðŸŽ¯ **1 endpoint principal**: `/query`
- ðŸ§  **InteligÃªncia automÃ¡tica**: Detecta contexto
- âš¡ **OtimizaÃ§Ãµes transparentes**: Sem configuraÃ§Ã£o
- ðŸ”„ **Compatibilidade total**: Funciona para todos

### **Todos podem usar `/query`:**
- **MCP** â†’ Direto, sem parÃ¢metros extras
- **Cursor** â†’ Com contexto especÃ­fico
- **Web apps** â†’ PadrÃ£o simples
- **CLI tools** â†’ Flexibilidade total

**ðŸŽ‰ Uma API para governar todas elas!** ðŸŽ¯ 